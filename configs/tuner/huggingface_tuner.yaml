_target_: src.tuners.huggingface_tuner.HuggingFaceTuner
hparams:
  pretrained_model_name:
    - beomi/OPEN-SOLAR-KO-10.7B
  lr:
    low: 0.00005
    high: 0.0002
    log: False
  period:
    low: 1
    high: 10
    log: False
  eta_min:
    low: 0.0000125
    high: 0.00005
    log: False

module_params:
  is_preprocessed: ${is_preprocessed}
  custom_data_encoder_path: ${custom_data_encoder_path}
  merged_model_path: ${merged_model_path}
  model_execution_mode: ${mode}
  quantization_type: ${quantization_type}
  quantization_config:
    load_in_4bit: ${quantization_config.load_in_4bit}
    bnb_4bit_quant_type: ${quantization_config.bnb_4bit_quant_type}
    bnb_4bit_use_double_quant: ${quantization_config.bnb_4bit_use_double_quant}
    bnb_4bit_compute_dtype: ${quantization_config.bnb_4bit_compute_dtype}
  peft_type: ${peft_type}
  peft_config:
    r: ${peft_config.r}
    lora_alpha: ${peft_config.lora_alpha}
    target_modules: ${peft_config.target_modules}
    lora_dropout: ${peft_config.lora_dropout}
    bias: ${peft_config.bias}
    task_type: ${peft_config.task_type}
  interval: step
  options: ${options}
  target_max_length: ${target_max_length}
  target_min_length: ${target_min_length}
  per_device_save_path: ${per_device_save_path}
  target_column_name: ${target_column_name}
  devices: ${devices}
  accelerator: ${accelerator}
  strategy: ${strategy}
  log_every_n_steps: ${log_every_n_steps}
  precision: ${precision}
  accumulate_grad_batches: ${accumulate_grad_batches}
  gradient_clip_val: ${gradient_clip_val}
  gradient_clip_algorithm: ${gradient_clip_algorithm}
  max_epochs: ${epoch}
  monitor: ${monitor}
  mode: ${tracking_direction}
  patience: ${patience}
  min_delta: ${min_delta}

direction: minimize
seed: ${seed}
num_trials: ${num_trials}
hparams_save_path: ${hparams_save_path}